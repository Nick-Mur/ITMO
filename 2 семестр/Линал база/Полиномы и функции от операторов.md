# Раздел 9: Полиномы и функции от операторов

## 1. Введение и мотивация

Мы знаем, что операторы можно складывать, умножать на скаляры и компонировать (перемножать). Это наводит на мысль: а что если подставить оператор $\phi$ в обычный полином $p(t) = a_k t^k + \dots + a_1 t + a_0$? Мы можем естественным образом определить **операторный полином** $p(\phi) = a_k \phi^k + \dots + a_1 \phi + a_0 id_V$. Изучение таких полиномов оказывается очень плодотворным:

*   **Аннулирующие полиномы:** Существуют ли ненулевые полиномы $p(t)$, такие что $p(\phi) = \mathbf{0}$ (нулевой оператор)? Оказывается, да, и это утверждает фундаментальная **теорема Гамильтона-Кэли**. Полином, "аннулирующий" оператор, несет важную информацию о его структуре. Существует **минимальный аннулирующий полином**, который тесно связан с ЖНФ оператора.
*   **Вычисление степеней и обратного:** Знание аннулирующего полинома позволяет эффективно вычислять высокие степени оператора $\phi^N$ или даже обратный оператор $\phi^{-1}$ (если он существует), не прибегая к прямому матричному умножению или обращению.
*   **Функции от операторов:** Идею подстановки оператора в полином можно обобщить на более широкий класс функций, например, на аналитические функции, такие как $e^t$, $\sin t$, $\cos t$. Как определить $e^\phi$? Это возможно, и результат $f(\phi)$ тоже является линейным оператором.
*   **Приложения:** Функции от операторов (и матриц) критически важны:
    *   **Решение систем линейных дифференциальных уравнений:** Решение системы $\frac{d\vec{x}}{dt} = A\vec{x}$ выражается через **матричную экспоненту** $e^{At}$. Умение вычислять $e^{At}$ (особенно с использованием ЖНФ) является ключевым.
    *   **Квантовая механика:** Эволюция квантовой системы описывается унитарным оператором $U(t) = e^{-iHt/\hbar}$, где $H$ — оператор Гамильтона (энергии).
    *   **Теория управления, обработка сигналов, графы:** Различные функции от матриц (например, матричный синус/косинус, матричный логарифм) возникают в этих и других областях.

Наша цель — определить полиномы и функции от операторов, изучить их свойства, понять роль теоремы Гамильтона-Кэли и научиться вычислять $f(\phi)$ или $f(A)$, особенно для диагонализируемых операторов и операторов в ЖНФ.

## 2. Основные определения и обозначения

Пусть $\phi \in \operatorname{End}(V)$, $\dim V = n < \infty$.

*   **Операторный полином:**
    Если $p(t) = a_k t^k + a_{k-1} t^{k-1} + \dots + a_1 t + a_0$ — полином с коэффициентами $a_i$ из поля $K$, то **операторный полином** $p(\phi)$ определяется как:
    $$ p(\phi) = a_k \phi^k + a_{k-1} \phi^{k-1} + \dots + a_1 \phi + a_0 id_V $$
    где $\phi^j = \phi \circ \dots \circ \phi$ ($j$ раз), $\phi^1 = \phi$, $\phi^0 = id_V$. Результат $p(\phi)$ — это тоже линейный оператор из $\operatorname{End}(V)$.

*   **Аннулирующий полином:**
    Ненулевой полином $p(t)$ называется **аннулирующим** для оператора $\phi$, если $p(\phi) = \mathbf{0}$ (нулевой оператор).

*   **Минимальный аннулирующий полином:**
    Среди всех аннулирующих полиномов оператора $\phi$ существует единственный полином с наименьшей степенью и старшим коэффициентом, равным 1. Он называется **минимальным (аннулирующим) полиномом** оператора $\phi$ и обозначается $\mu_\phi(t)$.
    *   Любой другой аннулирующий полином делится на минимальный полином.

*   **Спектральный проектор (для диагонализируемых операторов):**
    Если $\phi$ диагонализируем и $V = \bigoplus_{i=1}^s V_{\lambda_i}$, то **спектральным проектором** $P_i$ на подпространство $V_{\lambda_i}$ называется оператор, который любой вектор $v = v_1 + \dots + v_s$ (где $v_j \in V_{\lambda_j}$) отображает в его компоненту $v_i$: $P_i(v) = v_i$. Эти проекторы обладают свойствами:
    *   $P_i^2 = P_i$
    *   $P_i P_j = 0$ при $i \neq j$
    *   $\sum_{i=1}^s P_i = id_V$
    *   $\phi = \sum_{i=1}^s \lambda_i P_i$ (спектральное разложение)
    *   $\operatorname{Im} P_i = V_{\lambda_i}$, $\ker P_i = \bigoplus_{j \neq i} V_{\lambda_j}$

*   **Функция от оператора (определение через полиномы):**
    Если $f(t)$ — функция, определенная на спектре оператора $\phi$ (т.е. значения $f(\lambda_i)$ известны для всех $\lambda_i \in \operatorname{Spec}(\phi)$), то можно определить $f(\phi)$ как операторный полином $g(\phi)$, где $g(t)$ — полином, который принимает те же значения, что и $f(t)$ на спектре $\phi$, т.е. $g(\lambda_i) = f(\lambda_i)$ для всех $i$. Если учитывать кратности корней (или структуру ЖНФ), то нужно потребовать совпадения значений производных $g^{(j)}(\lambda_i) = f^{(j)}(\lambda_i)$ до определенного порядка. Такой полином (например, интерполяционный полином Лагранжа-Сильвестра) всегда существует. Значение $f(\phi) = g(\phi)$ не зависит от выбора такого полинома $g(t)$ (при условии, что $g(t)$ "правильно" интерполирует $f(t)$ на спектре с учетом кратностей/ЖНФ).

*   **Функция от диагональной матрицы:**
    Если $D = \operatorname{diag}(\lambda_1, \dots, \lambda_n)$, то
    $$ f(D) = \operatorname{diag}(f(\lambda_1), \dots, f(\lambda_n)) $$

*   **Функция от жордановой клетки:**
    Если $J = J_k(\lambda)$, то $f(J)$ вычисляется по формуле (требующей знания производных $f$ в точке $\lambda$):
    $$ f(J_k(\lambda)) = \begin{pmatrix} f(\lambda) & \frac{f'(\lambda)}{1!} & \frac{f''(\lambda)}{2!} & \dots & \frac{f^{(k-1)}(\lambda)}{(k-1)!} \\ 0 & f(\lambda) & \frac{f'(\lambda)}{1!} & \dots & \frac{f^{(k-2)}(\lambda)}{(k-2)!} \\ 0 & 0 & f(\lambda) & \dots & \frac{f^{(k-3)}(\lambda)}{(k-3)!} \\ \vdots & \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & 0 & \dots & f(\lambda) \end{pmatrix} $$

## 3. Ключевые утверждения (теоремы/свойства)

1.  **Теорема Гамильтона-Кэли:** Любой линейный оператор $\phi$ на конечномерном пространстве $V$ аннулируется своим характеристическим многочленом:
    $$ \chi_\phi(\phi) = \mathbf{0} $$
    То же верно для матриц: если $A$ — квадратная матрица и $\chi_A(\lambda) = \det(A - \lambda I)$ — ее характеристический многочлен, то $\chi_A(A) = \mathbf{0}$ (нулевая матрица).
2.  **Связь минимального и характеристического полиномов:** Минимальный полином $\mu_\phi(t)$ всегда делит характеристический полином $\chi_\phi(t)$. Кроме того, $\mu_\phi(t)$ и $\chi_\phi(t)$ имеют одни и те же корни (собственные значения $\phi$), но, возможно, с разными кратностями.
3.  **Критерий диагонализируемости через минимальный полином:** Оператор $\phi$ диагонализируем над полем $K$ тогда и только тогда, когда его минимальный полином $\mu_\phi(t)$ разлагается на линейные множители над $K$ и все его корни имеют кратность 1.
4.  **Инвариантность подпространств:** Если подпространство $U$ инвариантно относительно $\phi$, то оно инвариантно и относительно любого операторного полинома $p(\phi)$.
5.  **Спектр полинома от оператора:** Если $\lambda \in \operatorname{Spec}(\phi)$, то $p(\lambda) \in \operatorname{Spec}(p(\phi))$. Более того, если $\phi$ диагонализируем с собственными значениями $\lambda_1, \dots, \lambda_n$ (с учетом кратностей), то $p(\phi)$ тоже диагонализируем с собственными значениями $p(\lambda_1), \dots, p(\lambda_n)$.
6.  **Вычисление функции от оператора через ЖНФ:** Если $A = T J T^{-1}$, где $J$ — ЖНФ матрицы $A$, то
    $$ f(A) = T f(J) T^{-1} $$
    Матрица $f(J)$ вычисляется применением функции $f$ к каждой жордановой клетке $J_k(\lambda)$ в $J$ по формуле, приведенной выше.

## 4. Практические примеры — пошаговый разбор

**Пример 1: Теорема Гамильтона-Кэли и вычисление $A^2$.**

*   **Постановка:** Пусть $A = \begin{pmatrix} 4 & -2 \\ 1 & 1 \end{pmatrix}$. Мы знаем (из Раздела 7), что $\chi_A(\lambda) = \lambda^2 - 5\lambda + 6$. Проверить теорему Гамильтона-Кэли и использовать ее для вычисления $A^2$.
*   **Шаг 1: Проверить $\chi_A(A) = 0$.** Вычисляем $A^2 - 5A + 6I$:
    $$ A^2 = \begin{pmatrix} 4 & -2 \\ 1 & 1 \end{pmatrix} \begin{pmatrix} 4 & -2 \\ 1 & 1 \end{pmatrix} = \begin{pmatrix} 16-2 & -8-2 \\ 4+1 & -2+1 \end{pmatrix} = \begin{pmatrix} 14 & -10 \\ 5 & -1 \end{pmatrix} $$
    $$ 5A = 5 \begin{pmatrix} 4 & -2 \\ 1 & 1 \end{pmatrix} = \begin{pmatrix} 20 & -10 \\ 5 & 5 \end{pmatrix} $$
    $$ 6I = 6 \begin{pmatrix} 1 & 0 \\ 0 & 1 \end{pmatrix} = \begin{pmatrix} 6 & 0 \\ 0 & 6 \end{pmatrix} $$
    $$ A^2 - 5A + 6I = \begin{pmatrix} 14 & -10 \\ 5 & -1 \end{pmatrix} - \begin{pmatrix} 20 & -10 \\ 5 & 5 \end{pmatrix} + \begin{pmatrix} 6 & 0 \\ 0 & 6 \end{pmatrix} = \begin{pmatrix} 14-20+6 & -10-(-10)+0 \\ 5-5+0 & -1-5+6 \end{pmatrix} = \begin{pmatrix} 0 & 0 \\ 0 & 0 \end{pmatrix} $$
    Теорема выполнена.
*   **Шаг 2: Выразить $A^2$ из аннулирующего соотношения.** Из $A^2 - 5A + 6I = 0$ следует:
    $$ A^2 = 5A - 6I $$
*   **Шаг 3: Вычислить $A^2$ по этой формуле.**
    $$ A^2 = 5 \begin{pmatrix} 4 & -2 \\ 1 & 1 \end{pmatrix} - 6 \begin{pmatrix} 1 & 0 \\ 0 & 1 \end{pmatrix} = \begin{pmatrix} 20 & -10 \\ 5 & 5 \end{pmatrix} - \begin{pmatrix} 6 & 0 \\ 0 & 6 \end{pmatrix} = \begin{pmatrix} 14 & -10 \\ 5 & -1 \end{pmatrix} $$
    Результат совпал с прямым вычислением $A^2$.

**Пример 2: Функция от диагонализируемого оператора.**

*   **Постановка:** Для оператора $\phi$ из Примера 1 ($A = \begin{pmatrix} 4 & -2 \\ 1 & 1 \end{pmatrix}$) вычислить $e^\phi$ (или $e^A$).
*   **Шаг 1: Найти диагональную форму и матрицу перехода.** Мы знаем из Раздела 7, что $\lambda_1=2, \lambda_2=3$, $D = \begin{pmatrix} 2 & 0 \\ 0 & 3 \end{pmatrix}$ и $T = \begin{pmatrix} 1 & 2 \\ 1 & 1 \end{pmatrix}$, причем $A = T D T^{-1}$.
*   **Шаг 2: Вычислить функцию от диагональной матрицы.**
    $$ e^D = \begin{pmatrix} e^2 & 0 \\ 0 & e^3 \end{pmatrix} $$
*   **Шаг 3: Использовать формулу $f(A) = T f(D) T^{-1}$.** Нам нужен $T^{-1} = \begin{pmatrix} -1 & 2 \\ 1 & -1 \end{pmatrix}$.
    $$ e^A = T e^D T^{-1} = \begin{pmatrix} 1 & 2 \\ 1 & 1 \end{pmatrix} \begin{pmatrix} e^2 & 0 \\ 0 & e^3 \end{pmatrix} \begin{pmatrix} -1 & 2 \\ 1 & -1 \end{pmatrix} $$
    $$ e^A = \begin{pmatrix} 1 & 2 \\ 1 & 1 \end{pmatrix} \begin{pmatrix} -e^2 & 2e^2 \\ e^3 & -e^3 \end{pmatrix} $$
    $$ e^A = \begin{pmatrix} 1(-e^2) + 2(e^3) & 1(2e^2) + 2(-e^3) \\ 1(-e^2) + 1(e^3) & 1(2e^2) + 1(-e^3) \end{pmatrix} = \begin{pmatrix} 2e^3 - e^2 & 2e^2 - 2e^3 \\ e^3 - e^2 & 2e^2 - e^3 \end{pmatrix} $$
*   **Ответ:** $e^A = \begin{pmatrix} 2e^3 - e^2 & 2e^2 - 2e^3 \\ e^3 - e^2 & 2e^2 - e^3 \end{pmatrix}$.

**Пример 3: Функция от жордановой клетки.**

*   **Постановка:** Вычислить $e^{Jt}$ для $J = J_2(1) = \begin{pmatrix} 1 & 1 \\ 0 & 1 \end{pmatrix}$ (где $t$ — параметр).
*   **Шаг 1: Определить функцию.** Нам нужна функция $f(x) = e^{xt}$ от матрицы $J$. Ее производная $f'(x) = t e^{xt}$.
*   **Шаг 2: Применить формулу для $f(J_k(\lambda))$.** Здесь $k=2$, $\lambda=1$.
    $$ f(J) = \begin{pmatrix} f(1) & \frac{f'(1)}{1!} \\ 0 & f(1) \end{pmatrix} $$
*   **Шаг 3: Подставить значения.** $f(1) = e^{1 \cdot t} = e^t$. $f'(1) = t e^{1 \cdot t} = t e^t$.
    $$ e^{Jt} = \begin{pmatrix} e^t & t e^t \\ 0 & e^t \end{pmatrix} $$
*   **Ответ:** $e^{Jt} = e^t \begin{pmatrix} 1 & t \\ 0 & 1 \end{pmatrix}$. Это используется при решении систем ДУ с матрицей, имеющей такую ЖНФ.

## 5. Задачи для самопроверки

1.  Найдите минимальный аннулирующий полином для матрицы $A = \begin{pmatrix} 2 & 0 & 0 \\ 0 & 2 & 1 \\ 0 & 0 & 2 \end{pmatrix}$.
2.  Используя теорему Гамильтона-Кэли, найдите $A^{-1}$ для $A = \begin{pmatrix} 1 & 2 \\ 3 & 4 \end{pmatrix}$.
3.  Пусть $\phi$ — оператор проекции на подпространство $U$ параллельно $W$ ($V=U \oplus W$). Какой полином аннулирует $\phi$? Найдите минимальный полином.
4.  Вычислите $\sin(A)$ для $A = \begin{pmatrix} \pi & 0 \\ 0 & \pi/2 \end{pmatrix}$.
5.  Вычислите $J^3$ для $J = J_3(0) = \begin{pmatrix} 0 & 1 & 0 \\ 0 & 0 & 1 \\ 0 & 0 & 0 \end{pmatrix}$.

## 6. Краткое резюме

*   **Операторный полином $p(\phi)$:** Естественное обобщение понятия полинома.
*   **Теорема Гамильтона-Кэли:** $\chi_\phi(\phi) = \mathbf{0}$. Характеристический полином аннулирует оператор.
*   **Минимальный полином $\mu_\phi(t)$:** Аннулирующий полином наименьшей степени (делящий все остальные). Связан со структурой ЖНФ.
*   **Функция от оператора $f(\phi)$:** Может быть определена через интерполяционные полиномы или (для аналитических функций) через ряды.
*   Вычисление $f(A)$ упрощается, если $A$ диагональна ($f(D) = \operatorname{diag}(f(\lambda_i))$) или находится в ЖНФ ($f(A) = T f(J) T^{-1}$, где $f(J)$ вычисляется по клеткам).
*   Для жордановой клетки $J_k(\lambda)$ матрица $f(J_k(\lambda))$ имеет $f(\lambda)$ на диагонали